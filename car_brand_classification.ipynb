{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9f9ea4-032a-4ac0-a968-5c8c262ce0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # matematiksel işlemler için kullanılan kütüphane\n",
    "import pandas as pd # veri işleme kütüphanesi\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        print(os.path.join(dirname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3197ddeb-52a6-45de-b21f-2891c2d9f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28f01ec-ee58-4854-9529-232c2873081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04df25ce-c39d-41d5-85be-a2507bd53f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a46a85-c486-4b6e-a649-a5be384d069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'  #kernel died şeklinde alınan hataya karşılık eklendi\n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac48562-14e4-49eb-8f97-6e2459935c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4514 images belonging to 7 classes.\n",
      "Found 813 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "# Eğitim veri seti için ImageDataGenerator objesi oluşturur. \n",
    "#Bu, görüntülerde çeşitli rastgele dönüşümler (döndürme, ölçeklendirme, kaydırma vb.) uygular. \n",
    "# Bu teknik, modelin genelleme yeteneğini artırmak için kullanılır.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    ")\n",
    "# Test veri seti için ImageDataGenerator objesi oluşturur. \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Eğitim veri setini okur, ölçeklendirir.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/Cars_Dataset/train',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        class_mode=\"sparse\",\n",
    ")  \n",
    "# Test veri setini okur, ölçeklendirir.\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/Cars_Dataset/test',\n",
    "        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "        class_mode=\"sparse\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687e9d9d-04e4-4b65-b636-be0c2e1dee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 3. 6. 4. 3. 2. 0. 3. 6. 2. 0. 1. 5. 4. 6. 0. 6. 0. 2. 4. 4. 5. 3. 6.\n",
      " 2. 6. 3. 6. 2. 5. 4. 0.]\n",
      "[[[1.89044461e-01 2.12573871e-01 2.72877485e-01]\n",
      "  [2.17957750e-01 2.41487160e-01 3.03005397e-01]\n",
      "  [2.48691663e-01 2.72221088e-01 3.34953904e-01]\n",
      "  ...\n",
      "  [3.52517888e-02 5.88376448e-02 2.86302745e-01]\n",
      "  [6.65611252e-02 1.05724044e-01 5.80253825e-02]\n",
      "  [5.80882058e-02 8.94957483e-02 9.38377231e-02]]\n",
      "\n",
      " [[1.76710084e-01 1.95944324e-01 2.52278000e-01]\n",
      "  [2.07714394e-01 2.28770524e-01 2.84496903e-01]\n",
      "  [2.36092836e-01 2.58970857e-01 3.14089954e-01]\n",
      "  ...\n",
      "  [4.30947468e-02 7.05244765e-02 2.29329944e-01]\n",
      "  [7.45028630e-02 1.17636643e-01 5.07159239e-05]\n",
      "  [5.25289886e-02 7.99656659e-02 1.25604659e-01]]\n",
      "\n",
      " [[2.05499142e-01 2.18906567e-01 2.72801965e-01]\n",
      "  [2.18385711e-01 2.31185839e-01 2.86903113e-01]\n",
      "  [2.43223354e-01 2.55416155e-01 3.12955350e-01]\n",
      "  ...\n",
      "  [5.10364808e-02 8.24370757e-02 1.71355277e-01]\n",
      "  [6.89554587e-02 1.08125322e-01 3.17391492e-02]\n",
      "  [4.70588282e-02 7.05882385e-02 1.56862751e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6.27451017e-02 9.80392247e-02 2.11764723e-01]\n",
      "  [6.27451017e-02 9.80392247e-02 2.11764723e-01]\n",
      "  [3.45401950e-02 7.92359486e-02 1.83559820e-01]\n",
      "  ...\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]]\n",
      "\n",
      " [[6.27451017e-02 9.80392247e-02 2.11764723e-01]\n",
      "  [5.56599349e-02 9.33157727e-02 2.04679549e-01]\n",
      "  [2.75028497e-02 7.45227784e-02 1.76418737e-01]\n",
      "  ...\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]]\n",
      "\n",
      " [[6.27451017e-02 9.80392247e-02 2.11764723e-01]\n",
      "  [4.85123731e-02 8.85507390e-02 1.97531998e-01]\n",
      "  [3.38562354e-02 7.61111230e-02 1.70065343e-01]\n",
      "  ...\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]\n",
      "  [5.49019650e-02 7.84313753e-02 2.03921586e-01]]]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for image_batch, label_batch in train_generator:\n",
    "    print(label_batch)\n",
    "    print(image_batch[0])\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4d4d6b-8896-4f92-8642-b5406538cf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Audi',\n",
       " 'Hyundai Creta',\n",
       " 'Mahindra Scorpio',\n",
       " 'Rolls Royce',\n",
       " 'Swift',\n",
       " 'Tata Safari',\n",
       " 'Toyota Innova']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_generator.class_indices.keys())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d46d94-7403-4533-a68a-99e51950b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01176471 0.05882353 0.01960784]\n",
      "  [0.         0.04313726 0.00392157]\n",
      "  [0.         0.01568628 0.        ]\n",
      "  ...\n",
      "  [0.5882353  0.67058825 0.5411765 ]\n",
      "  [0.2901961  0.37254903 0.24313727]\n",
      "  [0.3803922  0.46274513 0.30980393]]\n",
      "\n",
      " [[0.         0.02745098 0.        ]\n",
      "  [0.00392157 0.0509804  0.01176471]\n",
      "  [0.03529412 0.07450981 0.03921569]\n",
      "  ...\n",
      "  [0.21960786 0.3019608  0.17254902]\n",
      "  [0.33333334 0.41960788 0.2784314 ]\n",
      "  [0.21568629 0.29803923 0.12941177]]\n",
      "\n",
      " [[0.         0.03529412 0.        ]\n",
      "  [0.02352941 0.0627451  0.02745098]\n",
      "  [0.0509804  0.09019608 0.05490196]\n",
      "  ...\n",
      "  [0.18039216 0.26666668 0.1254902 ]\n",
      "  [0.19607845 0.28235295 0.14117648]\n",
      "  [0.25882354 0.34509805 0.16078432]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.45098042 0.45098042 0.4901961 ]\n",
      "  [0.454902   0.454902   0.49411768]\n",
      "  [0.45882356 0.45882356 0.49803925]\n",
      "  ...\n",
      "  [0.34509805 0.37254903 0.41176474]\n",
      "  [0.34117648 0.36862746 0.40784317]\n",
      "  [0.33333334 0.36862746 0.4039216 ]]\n",
      "\n",
      " [[0.44705886 0.44705886 0.48627454]\n",
      "  [0.45098042 0.45098042 0.4901961 ]\n",
      "  [0.454902   0.454902   0.49411768]\n",
      "  ...\n",
      "  [0.34509805 0.37254903 0.41176474]\n",
      "  [0.34117648 0.36862746 0.40784317]\n",
      "  [0.33333334 0.36862746 0.4039216 ]]\n",
      "\n",
      " [[0.4431373  0.4431373  0.48235297]\n",
      "  [0.4431373  0.4431373  0.48235297]\n",
      "  [0.44705886 0.44705886 0.48627454]\n",
      "  ...\n",
      "  [0.34509805 0.37254903 0.41176474]\n",
      "  [0.34117648 0.36862746 0.40784317]\n",
      "  [0.32941177 0.3647059  0.40000004]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in test_generator:\n",
    "    print(image_batch[0])\n",
    "    break  #test veri üreteci için asıl çalıştığını ve ürettiği verinin nasıl göründüğünü gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf45f76-742e-472b-97cd-81766be275d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "sz = 128\n",
    "\n",
    "# CNN başlatılır\n",
    "model = Sequential()\n",
    "\n",
    "# İlk evrişim katmanı ve havuzlama \n",
    "model.add(Conv2D(64, (3, 3), input_shape=(sz, sz, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# İkinci evrişim katmanı ve havuzlama\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Üçüncü evrişim katmanı\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Katmanları düzleştirme\n",
    "model.add(Flatten())\n",
    "\n",
    "# Tamamen bağlı bir katman ekleme\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=7, activation='softmax'))   #birimler, sınıf sayısıyla eşleşmesini doğrular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f782c1-133b-4a34-8c61-62e929a5e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               12845184  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,966,471\n",
      "Trainable params: 12,966,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85ea02-339f-41e8-b7f1-66dbdfc0b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "142/142 [==============================] - 105s 727ms/step - loss: 1.9324 - accuracy: 0.2062 - val_loss: 1.8133 - val_accuracy: 0.2460\n",
      "Epoch 2/40\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 1.8138 - accuracy: 0.2809 - val_loss: 1.7445 - val_accuracy: 0.3419\n",
      "Epoch 3/40\n",
      "142/142 [==============================] - 94s 660ms/step - loss: 1.7729 - accuracy: 0.2935 - val_loss: 1.6595 - val_accuracy: 0.3493\n",
      "Epoch 4/40\n",
      "142/142 [==============================] - 92s 644ms/step - loss: 1.7250 - accuracy: 0.3257 - val_loss: 1.6745 - val_accuracy: 0.4034\n",
      "Epoch 5/40\n",
      "142/142 [==============================] - 94s 659ms/step - loss: 1.6827 - accuracy: 0.3445 - val_loss: 1.6398 - val_accuracy: 0.4194\n",
      "Epoch 6/40\n",
      "142/142 [==============================] - 91s 643ms/step - loss: 1.6628 - accuracy: 0.3624 - val_loss: 1.5721 - val_accuracy: 0.4170\n",
      "Epoch 7/40\n",
      "142/142 [==============================] - 93s 653ms/step - loss: 1.6404 - accuracy: 0.3704 - val_loss: 1.5432 - val_accuracy: 0.4576\n",
      "Epoch 8/40\n",
      "142/142 [==============================] - 90s 631ms/step - loss: 1.5958 - accuracy: 0.3872 - val_loss: 1.5356 - val_accuracy: 0.3936\n",
      "Epoch 9/40\n",
      "142/142 [==============================] - 92s 647ms/step - loss: 1.5715 - accuracy: 0.4081 - val_loss: 1.4350 - val_accuracy: 0.4994\n",
      "Epoch 10/40\n",
      "142/142 [==============================] - 91s 640ms/step - loss: 1.5586 - accuracy: 0.4114 - val_loss: 1.4234 - val_accuracy: 0.4649\n",
      "Epoch 11/40\n",
      "142/142 [==============================] - 95s 666ms/step - loss: 1.5098 - accuracy: 0.4373 - val_loss: 1.4170 - val_accuracy: 0.5129\n",
      "Epoch 12/40\n",
      "142/142 [==============================] - 102s 713ms/step - loss: 1.4862 - accuracy: 0.4435 - val_loss: 1.3398 - val_accuracy: 0.5375\n",
      "Epoch 13/40\n",
      "142/142 [==============================] - 106s 749ms/step - loss: 1.4454 - accuracy: 0.4674 - val_loss: 1.2622 - val_accuracy: 0.5560\n",
      "Epoch 14/40\n",
      "142/142 [==============================] - 92s 645ms/step - loss: 1.4447 - accuracy: 0.4723 - val_loss: 1.2738 - val_accuracy: 0.5547\n",
      "Epoch 15/40\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 1.3960 - accuracy: 0.4723 - val_loss: 1.2112 - val_accuracy: 0.5744\n",
      "Epoch 16/40\n",
      "114/142 [=======================>......] - ETA: 19s - loss: 1.3696 - accuracy: 0.4978"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Öğrenme oranını belirler. Bu değer, her iterasyonda modelin ağırlıklarının ne kadar hızlı güncelleneceğini kontrol eder.\n",
    "learning_rate = 0.001  \n",
    "\n",
    "# Adam optimizer'ını belirlenen öğrenme oranıyla başlatır.\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Model derlenir. \n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Model eğitilir.\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=40\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50da2f-a509-4f06-9062-24e92ef97020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test veri seti üzerinde modelin performansını değerlendirir.\n",
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7175ca-ea74-4661-b286-dfd8579cc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5424e0-96eb-44cb-a4ff-0d97ab8b03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d36d15-e8b3-4ef2-bd88-f8746533e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e68707-5273-4858-9ae7-a5e19e21c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "EPOCHS = 40\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8cb53-891f-4bac-9270-79b871affdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "def predict(model, img_path, classes):\n",
    "    # Görüntüyü yükler, modelin beklediği şekle getirir ve piksel değerlerini normalize eder\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
    "    \n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = classes[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca1a90-85d8-48ef-ae1e-5779338ef0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b965e-2843-4384-b5a1-3dedaeb6ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_generator:\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i], classes)\n",
    "        actual_class = classes[int(labels[i])] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c31324-4faa-449c-94c7-50276add9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Sabit değişkenler tanımlandı\n",
    "IMAGE_SIZE = [224,224]\n",
    "TRAIN_DIR = 'dataset/Cars_Dataset/train/*'\n",
    "\n",
    "# Üst katmanları dışlayacak şekilde yapılandırılmış, önceden eğitilmiş VGG16 modeli yüklenir\n",
    "base_model = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# VGG16'nın katmanlarını dondurulur\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Sınıf sayısını alınır\n",
    "folders = glob(TRAIN_DIR)\n",
    "num_classes = len(folders)\n",
    "\n",
    "# Yeni katmanlar eklenir\n",
    "x = Flatten()(base_model.output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Model tanımlanır\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Model derlenir\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Modelin yapısı gösterilir\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac36c9c-b666-427c-b858-b056490eb98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# Eğitim için veri artırmalı ve eğitim/test için veri artırmasız veri oluşturucuları tanımlanır\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range = 0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Dizinler tanımlanır\n",
    "TRAIN_DIR = 'dataset/Cars_Dataset/train/'\n",
    "TEST_DIR = 'dataset/Cars_Dataset/test/'\n",
    "\n",
    "# Görüntü özelliklerini tanımlanır\n",
    "TARGET_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "\n",
    "# Eğitim verileri yüklenir\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE)\n",
    "\n",
    "# Test verileri yüklenir\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE)\n",
    "\n",
    "# Model fit parametreleri tanımlanır\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = len(training_set)\n",
    "VALIDATION_STEPS = len(test_set)\n",
    "\n",
    "# Model iyileştirilir\n",
    "history = model.fit(\n",
    "    training_set, \n",
    "    validation_data=test_set,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a902cc-db03-4972-8086-b0a78a445033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Etiketler ve tahminler için boş listeler oluşturulur\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Test veri setinin her bir batch'i için tahminleri alınır\n",
    "for i in range(len(test_set)):\n",
    "    images, labels = next(test_set)\n",
    "    pred_probs = model.predict(images)\n",
    "    preds = np.argmax(pred_probs, axis=1)\n",
    "    true_labels = np.argmax(labels, axis=1)\n",
    "\n",
    "    y_true.extend(true_labels)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "# Sınıflandırma raporunu hesaplar ve yazdırır\n",
    "class_labels = list(test_set.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669b23b-7faf-4fc4-b847-72468e9a8a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
